{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "\n",
    "random.seed(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - Movie ratings dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is derived from the [MovieLens \"ml-latest-small\"](https://grouplens.org/datasets/movielens/latest/) dataset.   \n",
    "[F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. <https://doi.org/10.1145/2827872>]\n",
    "\n",
    "The original dataset has  9000 movies rated by 600 users. The dataset has been reduced in size to focus on movies from the years since 2000. This dataset consists of ratings on a scale of 0.5 to 5 in 0.5 step increments. The reduced dataset has $n_u = 443$ users, and $n_m= 4778$ movies. \n",
    "\n",
    "Below, you will load the movie dataset into the variables $Y$ and $R$.\n",
    "\n",
    "The matrix $Y$ (a  $n_m \\times n_u$ matrix) stores the ratings $y^{(i,j)}$. The matrix $R$ is an binary-valued indicator matrix, where $R(i,j) = 1$ if user $j$ gave a rating to movie $i$, and $R(i,j)=0$ otherwise. \n",
    "\n",
    "Throughout this part of the exercise, you will also be working with the\n",
    "matrices, $\\mathbf{X}$, $\\mathbf{W}$ and $\\mathbf{b}$: \n",
    "\n",
    "$$\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "--- (\\mathbf{x}^{(0)})^T --- \\\\\n",
    "--- (\\mathbf{x}^{(1)})^T --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (\\mathbf{x}^{(n_m-1)})^T --- \\\\\n",
    "\\end{bmatrix} , \\quad\n",
    "\\mathbf{W} = \n",
    "\\begin{bmatrix}\n",
    "--- (\\mathbf{w}^{(0)})^T --- \\\\\n",
    "--- (\\mathbf{w}^{(1)})^T --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (\\mathbf{w}^{(n_u-1)})^T --- \\\\\n",
    "\\end{bmatrix},\\quad\n",
    "\\mathbf{ b} = \n",
    "\\begin{bmatrix}\n",
    " b^{(0)}  \\\\\n",
    " b^{(1)} \\\\\n",
    "\\vdots \\\\\n",
    "b^{(n_u-1)} \\\\\n",
    "\\end{bmatrix}\\quad\n",
    "$$ \n",
    "\n",
    "The $i$-th row of $\\mathbf{X}$ corresponds to the\n",
    "feature vector $x^{(i)}$ for the $i$-th movie, and the $j$-th row of\n",
    "$\\mathbf{W}$ corresponds to one parameter vector $\\mathbf{w}^{(j)}$, for the\n",
    "$j$-th user. Both $x^{(i)}$ and $\\mathbf{w}^{(j)}$ are $n$-dimensional\n",
    "vectors. For the purposes of this exercise, you will use $n=10$, and\n",
    "therefore, $\\mathbf{x}^{(i)}$ and $\\mathbf{w}^{(j)}$ have 10 elements.\n",
    "Correspondingly, $\\mathbf{X}$ is a\n",
    "$n_m \\times 10$ matrix and $\\mathbf{W}$ is a $n_u \\times 10$ matrix.\n",
    "\n",
    "We will start by loading the movie ratings dataset to understand the structure of the data.\n",
    "We will load $Y$ and $R$ with the movie dataset.  \n",
    "We'll also load $\\mathbf{X}$, $\\mathbf{W}$, and $\\mathbf{b}$ with pre-computed values. These values will be learned later in the lab, but we'll use pre-computed values to develop the cost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df_movies_original = pd.read_csv('data\\movies\\movies.csv')\n",
    "df_ratings_original = pd.read_csv('data\\movies\\\\ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = df_movies_original.copy()\n",
    "df_ratings = df_ratings_original.copy()\n",
    "\n",
    "years = [(str(i)) for i in range(2000, 2022)]\n",
    "df_movies['year'] = df_movies['title'].str.extract(r'\\((\\d{4})\\)')\n",
    "\n",
    "mask = df_movies['title'].str.contains('|'.join(years))\n",
    "df_movies = df_movies[mask]\n",
    "\n",
    "genres_one_hot_encoding = df_movies['genres'].str.get_dummies(sep='|')\n",
    "df_movies = pd.concat([df_movies, genres_one_hot_encoding], axis=1)\n",
    "\n",
    "df_movies.reset_index(inplace=True)\n",
    "df_movies.drop(columns=['index', 'genres', 'year', '(no genres listed)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_filtered_mask = df_ratings['movieId'].isin(df_movies['movieId'])\n",
    "df_ratings = df_ratings[ratings_filtered_mask]\n",
    "df_ratings.reset_index(inplace=True)\n",
    "df_ratings.drop(columns=['index', 'timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new ids\n",
    "new_movie_ids = df_movies.index\n",
    "new_user_ids = range(df_ratings['userId'].nunique())\n",
    "\n",
    "# Dictionarys to map old ids with new ones\n",
    "id_mapping = dict(zip(df_movies['movieId'], new_movie_ids))\n",
    "user_id_mapping = dict(zip(sorted(df_ratings['userId'].unique()), new_user_ids))\n",
    "\n",
    "df_ratings['movieId'] = df_ratings['movieId'].map(id_mapping)\n",
    "df_ratings['userId'] = df_ratings['userId'].map(user_id_mapping)\n",
    "df_movies['movieId'] = df_movies['movieId'].map(id_mapping)\n",
    "\n",
    "df_movies_with_title = df_movies.copy()\n",
    "\n",
    "df_movies.drop(columns=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       0        8     5.0\n",
       "1       0       56     5.0\n",
       "2       0       65     4.0\n",
       "3       0       73     4.0\n",
       "4       0       84     5.0"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  Action  Adventure  Animation  Children  Comedy  Crime  \\\n",
       "0        0       0          1          0         0       0      0   \n",
       "1        1       1          0          0         0       1      0   \n",
       "2        2       0          0          0         0       0      0   \n",
       "3        3       0          0          0         0       0      1   \n",
       "4        4       0          0          1         1       0      0   \n",
       "\n",
       "   Documentary  Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  Mystery  \\\n",
       "0            0      1        0          0       0     0        0        0   \n",
       "1            0      0        0          0       0     0        1        0   \n",
       "2            0      0        0          0       0     0        0        0   \n",
       "3            0      1        0          0       0     0        0        0   \n",
       "4            0      0        0          0       0     1        1        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0       1         0    0        0  \n",
       "1        0       0         0    0        0  \n",
       "2        0       1         0    0        0  \n",
       "3        0       0         0    0        0  \n",
       "4        0       0         0    0        0  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_movies.drop(columns='movieId')\n",
    "num_movies = X.shape[0]\n",
    "num_features = X.shape[1]\n",
    "num_users = df_ratings['userId'].nunique()\n",
    "R = np.zeros((num_movies, num_users))\n",
    "Y = np.zeros((num_movies, num_users))\n",
    "\n",
    "for index, row in df_ratings.iterrows():\n",
    "    # Movie index and user index for the matrixes\n",
    "    movie_index = int(row['movieId']) - 1  # Subtract 1 to adjust to base 0\n",
    "    user_id = int(row['userId']) - 1  # Subtract 1 to adjust to base 0\n",
    "    \n",
    "    # Fill R with 1 if user rated the movie\n",
    "    R[movie_index, user_id] = 1\n",
    "    \n",
    "    # Fill Y with corresponding rate\n",
    "    Y[movie_index, user_id] = row['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (4789, 458) R (4789, 458)\n",
      "X (4789, 19)\n",
      "num_features 19\n",
      "num_movies 4789\n",
      "num_users 458\n"
     ]
    }
   ],
   "source": [
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X\", X.shape)\n",
    "# print(\"W\", W.shape)\n",
    "# print(\"b\", b.shape)\n",
    "print(\"num_features\", num_features)\n",
    "print(\"num_movies\",   num_movies)\n",
    "print(\"num_users\",    num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for movie 1 : 2.708 / 5\n"
     ]
    }
   ],
   "source": [
    "#  From the matrix, we can compute statistics like average rating.\n",
    "tsmean =  np.mean(Y[0, R[0, :].astype(bool)])\n",
    "print(f\"Average rating for movie 1 : {tsmean:0.3f} / 5\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of a collaborative filtering recommender system is to generate two vectors: For each user, a 'parameter vector' that embodies the movie tastes of a user. For each movie, a feature vector of the same size which embodies some description of the movie. The dot product of the two vectors plus the bias term should produce an estimate of the rating the user might give to that movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will begin implementing the collaborative filtering learning\n",
    "algorithm. You will start by implementing the objective function. \n",
    "\n",
    "The collaborative filtering algorithm in the setting of movie\n",
    "recommendations considers a set of $n$-dimensional parameter vectors\n",
    "$\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)}$, $\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$ and $b^{(0)},...,b^{(n_u-1)}$, where the\n",
    "model predicts the rating for movie $i$ by user $j$ as\n",
    "$y^{(i,j)} = \\mathbf{w}^{(j)}\\cdot \\mathbf{x}^{(i)} + b^{(j)}$ . Given a dataset that consists of\n",
    "a set of ratings produced by some users on some movies, you wish to\n",
    "learn the parameter vectors $\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\n",
    "\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$  and $b^{(0)},...,b^{(n_u-1)}$ that produce the best fit (minimizes\n",
    "the squared error).\n",
    "\n",
    "You will complete the code in cofiCostFunc to compute the cost\n",
    "function for collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative filtering cost function\n",
    "\n",
    "The collaborative filtering cost function is given by\n",
    "$$J({\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\\mathbf{w}^{(0)},b^{(0)},...,\\mathbf{w}^{(n_u-1)},b^{(n_u-1)}})= \\left[ \\frac{1}{2}\\sum_{(i,j):r(i,j)=1}(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+ \\underbrace{\\left[\n",
    "\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "\\right]}_{regularization}\n",
    "\\tag{1}$$\n",
    "The first summation in (1) is \"for all $i$, $j$ where $r(i,j)$ equals $1$\" and could be written:\n",
    "\n",
    "$$\n",
    "= \\left[ \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+\\text{regularization}\n",
    "$$\n",
    "\n",
    "You should now write cofiCostFunc (collaborative filtering cost function) to return this cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "        X (ndarray (num_movies,num_features)): matrix of item features\n",
    "        W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "        b (ndarray (1, num_users)            : vector of user parameters\n",
    "        Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "        R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "        lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "        J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    \n",
    "    for j in range(nu):\n",
    "        for i in range(nm):\n",
    "            f_wxb = (np.dot(W[j], X[i]) + b[0][j])\n",
    "            J += R[i][j] * (f_wxb - Y[i][j])**2\n",
    "            \n",
    "            \n",
    "#     w_sum = 0\n",
    "#     for j in range(nu):\n",
    "#         for k in range(len(W[j])):\n",
    "#             w_sum += W[j][k]**2\n",
    "#     w_sum *= lambda_\n",
    "\n",
    "#     x_sum = 0\n",
    "#     for j in range(nu):\n",
    "#         print(X[j])\n",
    "#         for k in range(len(X[j])):\n",
    "#             print(X[j][k])\n",
    "#             x_sum += X[j][k]**2\n",
    "#     x_sum *= lambda_\n",
    "\n",
    "#     J += w_sum + x_sum\n",
    "\n",
    "    J *= 1/2\n",
    "    J += (lambda_/2) * (np.sum(np.square(W)) + np.sum(np.square(X)))\n",
    "    \n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorized Implementation**\n",
    "\n",
    "It is important to create a vectorized implementation to compute $J$, since it will later be called many times during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "        X (ndarray (num_movies,num_features)): matrix of item features\n",
    "        W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "        b (ndarray (1, num_users)            : vector of user parameters\n",
    "        Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "        R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "        lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "        J (float) : Cost\n",
    "    \"\"\"\n",
    "    X = tf.convert_to_tensor(X, dtype=tf.float64)\n",
    "    W = tf.convert_to_tensor(W, dtype=tf.float64)\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(num_users, num_features):\n",
    "    \"\"\"\n",
    "    Initializes the parameters W and b for collaborative filtering algorithm\n",
    "    \n",
    "    Args:\n",
    "    num_users (int): Number of users\n",
    "    num_features (int): Number of features\n",
    "    \n",
    "    Returns:\n",
    "    W (ndarray): Initialized matrix of user parameters\n",
    "    b (ndarray): Initialized vector of user parameters\n",
    "    \"\"\"\n",
    "    # Initialize W with random values\n",
    "    W = np.random.randn(num_users, num_features)\n",
    "    \n",
    "    # Initialize b with zeros\n",
    "    b = np.zeros((1, num_users))\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 304714.62\n",
      "Cost (with regularization): 319608.03\n"
     ]
    }
   ],
   "source": [
    "W, b = initialize_parameters(num_users, num_features)\n",
    "\n",
    "# Evaluate cost function\n",
    "J = cofi_cost_func(np.array(X), W, b, Y, R, 0)\n",
    "print(f\"Cost: {J:0.2f}\")\n",
    "\n",
    "# Evaluate cost function with regularization \n",
    "J = cofi_cost_func(np.array(X), W, b, Y, R, 1.5)\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 304714.62\n",
      "Cost (with regularization): 319608.03\n"
     ]
    }
   ],
   "source": [
    "# Evaluate cost function\n",
    "J = cofi_cost_func_v(np.array(X), W, b, Y, R, 0)\n",
    "print(f\"Cost: {J:0.2f}\")\n",
    "\n",
    "# Evaluate cost function with regularization \n",
    "J = cofi_cost_func_v(np.array(X), W, b, Y, R, 1.5)\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning movie recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for  Town & Country (2001)\n",
      "Rated 5.0 for  Town is Quiet, The (Ville est tranquille, La) (2000)\n",
      "Rated 2.0 for  Affair of the Necklace, The (2001)\n",
      "Rated 5.0 for  Frida (2002)\n",
      "Rated 5.0 for  Charlie's Angels: Full Throttle (2003)\n",
      "Rated 5.0 for  My Flesh and Blood (2003)\n",
      "Rated 3.0 for  Agent Cody Banks 2: Destination London (2004)\n",
      "Rated 5.0 for  The Machinist (2004)\n",
      "Rated 2.0 for  Stan Helsing (2009)\n",
      "Rated 5.0 for  Sex and the City 2 (2010)\n",
      "Rated 3.0 for  Twilight Saga: Eclipse, The (2010)\n",
      "Rated 1.0 for  Louis C.K.: Hilarious (2010)\n",
      "Rated 1.0 for  Incendies (2010)\n"
     ]
    }
   ],
   "source": [
    "my_ratings = np.zeros(num_movies)          #  Initialize my ratings\n",
    "\n",
    "# Check the file small_movie_list.csv for id of each movie in our dataset\n",
    "# For example, Toy Story 3 (2010) has ID 2700, so to rate it \"5\", you can set\n",
    "my_ratings[2700] = 5 \n",
    "\n",
    "#Or suppose you did not enjoy Persuasion (2007), you can set\n",
    "my_ratings[2609] = 2\n",
    "\n",
    "# We have selected a few movies we liked / did not like and the ratings we\n",
    "# gave are as follows:\n",
    "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
    "my_ratings[246]  = 5   # Shrek (2001)\n",
    "my_ratings[2716] = 3   # Inception\n",
    "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
    "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'Amélie Poulain, Le)\n",
    "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
    "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
    "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
    "my_ratings[2937] = 1   # Nothing to Declare (Rien à déclarer)\n",
    "my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for  {df_movies_with_title.loc[i,\"title\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new user ratings to Y \n",
    "Y = np.c_[my_ratings, Y]\n",
    "\n",
    "# Add new user indicator matrix to R\n",
    "R = np.c_[(my_ratings != 0).astype(int), R]\n",
    "\n",
    "# Normalize the Dataset\n",
    "Ymean = np.mean(Y, axis=1, keepdims=True)\n",
    "Ynorm = Y - Ymean\n",
    "\n",
    "# Multiplicar pelo indicador de presença de avaliação\n",
    "Ynorm = Ynorm * R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare to train the model. Initialize the parameters and select the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the collaborative filtering model. This will learn the parameters $\\mathbf{X}$, $\\mathbf{W}$, and $\\mathbf{b}$.\n",
    "\n",
    "The operations involved in learning $w$, $b$, and $x$ simultaneously do not fall into the typical 'layers' offered in the TensorFlow neural network package.  Consequently, the flow used in neural_networks.ipynb: Model, Compile(), Fit(), Predict(), are not directly applicable. Instead, we can use a custom training loop.\n",
    "\n",
    "Recalling the steps of gradient descent.\n",
    "- repeat until convergence:\n",
    "    - compute forward pass\n",
    "    - compute the derivatives of the loss relative to parameters\n",
    "    - update the parameters using the learning rate and the computed derivatives \n",
    "    \n",
    "TensorFlow has the marvelous capability of calculating the derivatives for you. This is shown below. Within the `tf.GradientTape()` section, operations on Tensorflow Variables are tracked. When `tape.gradient()` is later called, it will return the gradient of the loss relative to the tracked variables. The gradients can then be applied to the parameters using an optimizer. \n",
    "This is a very brief introduction to a useful feature of TensorFlow and other machine learning frameworks. Further information can be found by investigating \"custom training loops\" within the framework of interest.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 2474087.7\n",
      "Training loss at iteration 20: 144394.7\n",
      "Training loss at iteration 40: 57391.6\n",
      "Training loss at iteration 60: 28339.1\n",
      "Training loss at iteration 80: 16414.3\n",
      "Training loss at iteration 100: 10776.6\n",
      "Training loss at iteration 120: 7798.1\n",
      "Training loss at iteration 140: 6084.3\n",
      "Training loss at iteration 160: 5029.2\n",
      "Training loss at iteration 180: 4341.6\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    # Use TensorFlow’s GradientTape\n",
    "    # to record the operations used to compute the cost \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations\n",
    "Now compute the ratings for all the movies and users and display the movies that are recommended. These are based on the movies and ratings entered as `my_ratings[]` above. To predict the rating of movie $i$ for user $j$, you compute $\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}$. This can be computed for all ratings using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 5.70 for movie Class, The (Klass) (2007)\n",
      "Predicting rating 5.60 for movie Despicable Me (2010)\n",
      "Predicting rating 5.53 for movie It's All Gone Pete Tong (2004)\n",
      "Predicting rating 5.49 for movie Kate & Leopold (2001)\n",
      "Predicting rating 5.43 for movie Narc (2002)\n",
      "Predicting rating 5.34 for movie Ask the Dust (2006)\n",
      "Predicting rating 5.25 for movie Respiro (2002)\n",
      "Predicting rating 5.22 for movie Way of the Gun, The (2000)\n",
      "Predicting rating 5.19 for movie Looney Tunes: Back in Action (2003)\n",
      "Predicting rating 5.19 for movie Birth (2004)\n",
      "Predicting rating 5.19 for movie Charlie Bartlett (2007)\n",
      "Predicting rating 5.13 for movie Swimming Pool (2003)\n",
      "Predicting rating 5.12 for movie No Man's Land (2001)\n",
      "Predicting rating 5.12 for movie Ballad of Jack and Rose, The (2005)\n",
      "Predicting rating 5.11 for movie Majestic, The (2001)\n",
      "Predicting rating 5.10 for movie Human Nature (2001)\n",
      "Predicting rating 5.08 for movie Radio Day (2008)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5.0, Predicted 4.93 for Town & Country (2001)\n",
      "Original 5.0, Predicted 4.71 for Town is Quiet, The (Ville est tranquille, La) (2000)\n",
      "Original 2.0, Predicted 2.26 for Affair of the Necklace, The (2001)\n",
      "Original 5.0, Predicted 4.79 for Frida (2002)\n",
      "Original 5.0, Predicted 4.73 for Charlie's Angels: Full Throttle (2003)\n",
      "Original 5.0, Predicted 4.73 for My Flesh and Blood (2003)\n",
      "Original 3.0, Predicted 3.09 for Agent Cody Banks 2: Destination London (2004)\n",
      "Original 5.0, Predicted 4.74 for The Machinist (2004)\n",
      "Original 2.0, Predicted 2.23 for Stan Helsing (2009)\n",
      "Original 5.0, Predicted 4.78 for Sex and the City 2 (2010)\n",
      "Original 3.0, Predicted 3.07 for Twilight Saga: Eclipse, The (2010)\n",
      "Original 1.0, Predicted 1.36 for Louis C.K.: Hilarious (2010)\n",
      "Original 1.0, Predicted 1.43 for Incendies (2010)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using trained weights and biases\n",
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "movieList = list(df_movies_with_title['title'])\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
